{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nfrom PIL import Image\nimport torch\nimport os\nfrom torch import nn\nimport torch.nn.functional as F\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\n#wandb\n!pip install wandb -qqq\nimport wandb\n\n#torchvision\n#!pip install torchvision --upgrade\nimport torchvision","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:46:01.510241Z","iopub.execute_input":"2022-05-09T08:46:01.510630Z","iopub.status.idle":"2022-05-09T08:46:08.864305Z","shell.execute_reply.started":"2022-05-09T08:46:01.510582Z","shell.execute_reply":"2022-05-09T08:46:08.863376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Caricamento dei Dataset","metadata":{}},{"cell_type":"code","source":"#Carico i dataset di HM\ntrain = pd.read_json(\"../input/hatefulmeme/hm_data/hm_data/train.jsonl\",lines=True)\nval_seen = pd.read_json('../input/hatefulmeme/hm_data/hm_data/dev_seen.jsonl',lines=True)\nval_unseen = pd.read_json('../input/hatefulmeme/hm_data/hm_data/dev_unseen.jsonl',lines=True)\ntest_seen = pd.read_json('../input/hatefulmeme/hm_data/hm_data/test_seen.jsonl',lines=True)\ntest_unseen = pd.read_json('../input/hatefulmeme/hm_data/hm_data/test_unseen.jsonl',lines=True)\n\nmetadata_hateful = pd.concat([train, val_seen, val_unseen, test_seen, test_unseen], ignore_index=True)\n\n#Carico il dataset Misogyny\nmetadata_misogyny = pd.read_json(\"../input/misogynydataset/misogyny.jsonl\",lines=True)\nmetadata_misogyny_train = metadata_misogyny.sample(frac=0.79, random_state=42)\nmetadata_misogyny_test = metadata_misogyny.drop(metadata_misogyny_train.index).sample(frac=0.5, random_state=42)\n\n\n\n#Concateno i metadata e l'embedding del testo\nmetadata = pd.concat([metadata_hateful, metadata_misogyny_train], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:46:08.868071Z","iopub.execute_input":"2022-05-09T08:46:08.868294Z","iopub.status.idle":"2022-05-09T08:46:09.004309Z","shell.execute_reply.started":"2022-05-09T08:46:08.868269Z","shell.execute_reply":"2022-05-09T08:46:09.003621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata_misogyny_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:46:09.005563Z","iopub.execute_input":"2022-05-09T08:46:09.005823Z","iopub.status.idle":"2022-05-09T08:46:09.011236Z","shell.execute_reply.started":"2022-05-09T08:46:09.005791Z","shell.execute_reply":"2022-05-09T08:46:09.010345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = metadata.sample(frac=0.90, random_state=42)\nvalid_df = metadata.drop(train_df.index).sample(frac=0.5, random_state=42)\ntrain_df = train_df.reset_index()\nvalid_df = valid_df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:46:09.014343Z","iopub.execute_input":"2022-05-09T08:46:09.014809Z","iopub.status.idle":"2022-05-09T08:46:09.033601Z","shell.execute_reply.started":"2022-05-09T08:46:09.014773Z","shell.execute_reply":"2022-05-09T08:46:09.032988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:46:09.034834Z","iopub.execute_input":"2022-05-09T08:46:09.035076Z","iopub.status.idle":"2022-05-09T08:46:09.040028Z","shell.execute_reply.started":"2022-05-09T08:46:09.035041Z","shell.execute_reply":"2022-05-09T08:46:09.039305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:46:09.041421Z","iopub.execute_input":"2022-05-09T08:46:09.041878Z","iopub.status.idle":"2022-05-09T08:46:09.049789Z","shell.execute_reply.started":"2022-05-09T08:46:09.041843Z","shell.execute_reply":"2022-05-09T08:46:09.048902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"class JsonlDataset(torch.utils.data.Dataset):\n\n  def __init__(self, df, HM_text_embeds_path, HM_graph_embeds_path, MIS_text_embeds_path, MIS_graph_embeds_path):\n  \n    self.data = df\n    self.HM_text_embeds_path = HM_text_embeds_path\n    self.MIS_text_embeds_path = MIS_text_embeds_path\n    self.HM_graph_embeds = HM_graph_embeds_path\n    self.MIS_graph_embeds = MIS_graph_embeds_path\n    self.data_dir_mis = '../input/misogynydataset/img/'\n    self.data_dir_hm = '../input/hatefulmeme/hm_data/hm_data/'\n    \n  def __len__(self):\n    return len(self.data)\n\n  def __getitem__(self, index):\n\n    if torch.is_tensor(index):\n      index = index.tolist()\n    \n    #Controllo se siamo in HM o MIS\n    if 'jpg' in self.data['img'][index]:\n        #Questo è MIS\n        #Carico il testo\n        text = torch.FloatTensor(np.load(f'{self.MIS_text_embeds_path}/{self.data[\"id\"][index]}.npy'))\n        \n        #Carico il grafo\n        #Acquisisco l'embedding\n        #a = np.load(f'{self.MIS_graph_embeds}/{self.data[\"id\"][index]}.npy')\n        #Effettuo la media passando da [n,768] a [768]\n        #b = np.mean(a,axis=0)\n        #Trasformo in Tensore\n        #graph = torch.FloatTensor(b)\n        \n        #Carico l'immagine\n        image = Image.open(self.data_dir_mis+self.data['img'][index]).convert('RGB')\n        image = image.resize((256,256))\n        image = torchvision.transforms.functional.to_tensor(image)\n               \n    else:\n        #Questo è HM\n        #Carico il testo\n        text = torch.FloatTensor(np.load(f'{self.HM_text_embeds_path}/{self.data[\"id\"][index]}.npy'))\n        \n        #Carico il grafo\n        #Acquisisco l'embedding\n        #a = np.load(f'{self.HM_graph_embeds}/{self.data[\"id\"][index]}.npy')\n        #Effettuo la media passando da [n,768] a [768]\n        #b = np.mean(a,axis=0)\n        #Trasformo in Tensore\n        #graph = torch.FloatTensor(b)\n        \n        #Carico l'immagine\n        image = Image.open(self.data_dir_hm+self.data['img'][index]).convert('RGB')\n        image = image.resize((256,256))\n        image = torchvision.transforms.functional.to_tensor(image)\n\n    \n    label = torch.FloatTensor([self.data[\"label\"][index]])\n\n    return text,image,label #graph","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:46:09.051372Z","iopub.execute_input":"2022-05-09T08:46:09.051716Z","iopub.status.idle":"2022-05-09T08:46:09.063396Z","shell.execute_reply.started":"2022-05-09T08:46:09.051680Z","shell.execute_reply":"2022-05-09T08:46:09.062510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modello","metadata":{}},{"cell_type":"code","source":"class ImageEncoder(nn.Module):\n    def __init__(self, **kwargs):\n        super(ImageEncoder, self).__init__()\n        \n        #self.model = torchvision.models.resnet152(pretrained=True)\n        self.model = torchvision.models.resnet50(pretrained=True)\n        #self.model = torchvision.models.resnet18(pretrained=True)\n        #self.model = torchvision.models.efficientnet_b7(pretrained=True)\n        #self.model.fc = nn.Linear(self.model.fc.in_features, 768)\n\n        #Mi prendo tutti e 2048 elementi dell'ultimo avgpool2d\n        self.model = torch.nn.Sequential(*list(self.model.children())[:-1])\n\n        #Freeze of parameters\n        for param in self.model.parameters():\n            param.requires_grad = False\n        \n        #Riduco le features che arrivano dall'immagine\n        self.fc1 = nn.Linear(2048, 1024)\n        self.fc2 = nn.Linear(1024, 768)\n        \n        #Espando le features\n        #self.fc1_graph = nn.Linear(40, 200)\n        #self.fc2_graph = nn.Linear(200, 500)\n        #self.fc3_graph = nn.Linear(500, 768)\n        \n        #Concateno ora le feature dell'immagine con quelle testuali\n        self.fc3 = nn.Linear(768 + 768, 1300)\n        self.fc4 = nn.Linear(1300, 700)\n        self.fc5 = nn.Linear(700, 250)\n        self.fc6 = nn.Linear(250, 50)\n        self.fc7 = nn.Linear(50, 1)\n        \n        #Inserire un layer di dropout\n        self.dropout = nn.Dropout(0.3)\n\n    def forward(self, image, text):\n\n        #Forward immagine\n        x1 = self.model(image).squeeze()\n        x1 = F.relu(self.fc1(x1))\n        x1 = F.relu(self.fc2(x1))\n        \n        #Recupero il testo\n        x2 = text.squeeze(dim=1)\n        \n        #Espando il grafo\n        #x3 = F.relu(self.fc1_graph(graph))\n        #x3 = F.relu(self.fc2_graph(x3))\n        #x3 = F.relu(self.fc3_graph(x3))\n        #x3 = graph\n        \n        #concateno immagini e testo\n        x = torch.cat((x1, x2), dim=1) #x3\n        \n        x = self.dropout(x)\n        x = F.relu(self.fc3(x))\n        x = F.relu(self.fc4(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc5(x))\n        x = F.relu(self.fc6(x))\n        x = self.dropout(x)\n        x = self.fc7(x)\n\n        return torch.sigmoid(x)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:46:09.064796Z","iopub.execute_input":"2022-05-09T08:46:09.065296Z","iopub.status.idle":"2022-05-09T08:46:09.079461Z","shell.execute_reply.started":"2022-05-09T08:46:09.065262Z","shell.execute_reply":"2022-05-09T08:46:09.078638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset/Dataloader","metadata":{}},{"cell_type":"code","source":"#Dataset\ntrain_dataset = JsonlDataset(train_df, '../input/text-hm-embeds/content/text_embeds_hateful', '../input/h2v-768-complete/content/embeddings','../input/text-mis-embeds/content/text_embeds_misogyny','../input/misogyny-graph-h2v-lvl-1-complete/misogyny_complete_lvl_1_embedding')\nvalid_dataset = JsonlDataset(valid_df, '../input/text-hm-embeds/content/text_embeds_hateful', '../input/h2v-768-complete/content/embeddings','../input/text-mis-embeds/content/text_embeds_misogyny','../input/misogyny-graph-h2v-lvl-1-complete/misogyny_complete_lvl_1_embedding')\n\n#Dataloader\nBATCH_SIZE=32\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = 2)\nvalid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = 2)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:46:09.080709Z","iopub.execute_input":"2022-05-09T08:46:09.080961Z","iopub.status.idle":"2022-05-09T08:46:09.091247Z","shell.execute_reply.started":"2022-05-09T08:46:09.080924Z","shell.execute_reply":"2022-05-09T08:46:09.090638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Iperparametri","metadata":{}},{"cell_type":"code","source":"BertResModel=ImageEncoder()\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nBertResModel.to(DEVICE)\nprint('Modello caricato!')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:46:09.093501Z","iopub.execute_input":"2022-05-09T08:46:09.093837Z","iopub.status.idle":"2022-05-09T08:46:18.299616Z","shell.execute_reply.started":"2022-05-09T08:46:09.093801Z","shell.execute_reply":"2022-05-09T08:46:18.298018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.login()\n#pwd = '35b29dc1704ea7b50447995026737a8415a797d9'\n\noptimizer = torch.optim.AdamW(BertResModel.parameters(),lr=0.0001)\ncriterion_ce = torch.nn.BCELoss()\n\nEPOCHE = 30\nbest_F1 = 0.3\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, \n    mode='max', \n    factor=0.1, \n    patience=4, \n    threshold=0.001,\n    threshold_mode='rel', \n    cooldown=0, \n    min_lr=0, \n    eps=1e-08, \n    verbose=True,\n)\n\n\ntrain_logs = {\n    \n    'loss': [],\n    'accuracy': [],\n    \n}\n\nvalid_logs = {\n    \n    'loss': [],\n    'accuracy': [],\n    'F1': [],\n    'AUC': [],\n    \n}\n\nwandb.init(\n      # Set the project where this run will be logged\n      project=\"Augumented_HM+MIS\", \n      # Track hyperparameters and run metadata\n      config={\n      \"learning_rate\": 0.0001,\n      \"architecture\": \"CNN+transformer\",\n      \"dataset\": \"HatefulMemeDetection\",\n      \"epochs\": EPOCHE,\n      })","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:46:18.300950Z","iopub.execute_input":"2022-05-09T08:46:18.301201Z","iopub.status.idle":"2022-05-09T08:46:28.705457Z","shell.execute_reply.started":"2022-05-09T08:46:18.301166Z","shell.execute_reply":"2022-05-09T08:46:28.704699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, classification_report, confusion_matrix\n\ndef binary_acc(y_pred, y_gt):\n  \n    tres = 0.5\n    preds = (y_pred).detach().cpu().numpy() > tres\n    proba = (y_pred).detach().cpu().numpy()\n    out_label_ids = y_gt.detach().cpu().numpy()\n\n    return accuracy_score(out_label_ids, preds)\n\ndef class_report(y_pred, y_gt):\n    \n    tres = 0.5\n    preds = np.array(y_pred) > tres\n    \n    #target_names = ['benign', 'hateful']\n    \n    return classification_report(y_gt,preds, output_dict=True)\n\ndef f1(y_preds, y_gt):\n    \n    tres = 0.5\n    preds = np.array(y_preds) > tres\n    \n    return f1_score(y_gt, preds, average='micro')\n\ndef AUC(y_preds, y_gt):\n    \n    return roc_auc_score(y_gt, y_preds, average='micro')\n\ndef binary_acc2(y_pred, y_gt):\n  \n    tres = 0.5\n    preds = np.array(y_pred) > tres\n\n    return accuracy_score(y_gt, preds)\n\ndef unpack(lista):\n    unpack_lista=[]\n    for i in range(len(lista)):\n        for j in range(len(lista[i])):\n            unpack_lista.append(lista[i][j])\n    return unpack_lista","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:46:28.707116Z","iopub.execute_input":"2022-05-09T08:46:28.707380Z","iopub.status.idle":"2022-05-09T08:46:29.425298Z","shell.execute_reply.started":"2022-05-09T08:46:28.707339Z","shell.execute_reply":"2022-05-09T08:46:29.424599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ModelEval(model, valid_dataloader):\n    \n    #VALIDATION\n    print(\"VALIDATION...\")\n    loop_valid = tqdm(valid_dataloader)\n    running_loss_valid = 0.0\n    running_accuracy_valid = 0.0\n    \n    predizioni = []\n    GT = []\n\n    model.eval()\n    \n    with torch.no_grad():\n        for i, data in enumerate(loop_valid, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            text,image,label = data\n            text = text.to(device=DEVICE)\n            #graph = graph.to(device=DEVICE)\n            image = image.to(device=DEVICE)\n            label = label.to(device=DEVICE)\n\n            #forward\n            outputs = model(image, text)\n            valid_loss = criterion_ce(outputs, label)\n\n            #accuracy\n            valid_accuracy = binary_acc(outputs, label)\n\n            #Accumulo\n            running_loss_valid += valid_loss.item()\n            running_accuracy_valid += valid_accuracy.item()\n            \n            #Accumulo predizioni e gt\n            predizioni.append(outputs.detach().cpu().numpy())\n            GT.append(label.detach().cpu().numpy())\n                \n            #Aggiornamento loop    \n            loop_valid.set_postfix(loss = valid_loss.item(), accuracy = valid_accuracy.item())\n            \n        #LR_SCHEDULER    \n        scheduler.step(AUC(unpack(predizioni),unpack(GT)))\n                   \n    #STATISTICHE\n    valid_logs['loss'].append(running_loss_valid/len(valid_dataloader))\n    valid_logs['accuracy'].append((running_accuracy_valid)/len(valid_dataloader))\n    valid_logs['F1'].append(f1(unpack(predizioni),unpack(GT)))\n    valid_logs['AUC'].append(AUC(unpack(predizioni),unpack(GT)))\n    \n    print(f\"F1: {valid_logs['F1'][-1]:.4f}\")\n\n    #Aggiorno il logger\n    wandb.log(\n        {\n            ##\"valid_loss\": running_loss_valid/len(valid_dataloader), \n            ##\"valid_accuracy\": running_accuracy_valid/len(valid_dataloader)\n            \"valid_loss\": valid_logs['loss'][-1],\n            \"valid_accuracy\": valid_logs['accuracy'][-1],\n            \"F1\": valid_logs['F1'][-1],\n            \"AUC\": valid_logs['AUC'][-1],\n        },\n        step=epoch\n    \n    )\n    \n    #Salvo il modello su questo parametro, perciò lo ritorno\n    return valid_logs['F1'][-1]","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:46:29.426454Z","iopub.execute_input":"2022-05-09T08:46:29.427944Z","iopub.status.idle":"2022-05-09T08:46:29.442333Z","shell.execute_reply.started":"2022-05-09T08:46:29.427905Z","shell.execute_reply":"2022-05-09T08:46:29.441614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TRAINING\nmodel=BertResModel\nLOADER = train_dataloader\n\nfor epoch in range(EPOCHE):  # loop over the dataset multiple times\n\n    print(f\"Epoca: {epoch+1}\\n\")\n    print(\"TRAINING...\")\n    \n    \n    loop = tqdm(LOADER)\n    running_loss = 0.0\n    running_accuracy = 0.0\n    \n    model.train()\n    \n    for i, data in enumerate(loop):\n        # get the inputs; data is a list of [inputs, labels]\n        text, image, label = data\n        text = text.to(device=DEVICE)\n        #graph = graph.to(device=DEVICE)\n        image = image.to(device=DEVICE)\n        label = label.to(device=DEVICE)\n        \n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(image, text)\n        loss = criterion_ce(outputs, label)\n        loss.backward()\n        optimizer.step()\n  \n        #accuracy\n        acc = binary_acc(outputs, label)\n\n       \n        # print statistics\n        running_loss += loss.item()\n        running_accuracy += acc.item()\n        if i == len(LOADER)-1:    # print every mini-batches\n            print('loss media sul minibatch training: %.3f' %(running_loss/len(LOADER)))\n            print('accuracy media sul minibatch training: %.3f' %(running_accuracy/len(LOADER)))\n            train_logs['loss'].append(running_loss/len(LOADER))\n            train_logs['accuracy'].append((running_accuracy)/len(LOADER))\n\n            wandb.log({\"train_loss\": running_loss/len(LOADER), \"train_accuracy\": running_accuracy/len(LOADER),\"epoch\": epoch}, step=epoch)\n            \n            running_loss = 0.0\n\n            running_accuracy = 0.0\n\n        loop.set_postfix(loss = loss.item(),accuracy = acc.item())\n        \n    #Evaluation model   \n    valid_F1 = ModelEval(model, valid_dataloader)\n      \n\n    #Salvo il modello migliore su AUC\n    if valid_F1 > best_F1:\n        best_F1 = valid_F1\n        torch.save(model.state_dict(), f'./best_model_F1_{best_F1:.4f}_epoca_{epoch+1}.pth')\n        print('Model saved!')\n        \nprint('Finished Training')\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:46:29.444777Z","iopub.execute_input":"2022-05-09T08:46:29.445023Z","iopub.status.idle":"2022-05-09T10:03:53.415820Z","shell.execute_reply.started":"2022-05-09T08:46:29.444994Z","shell.execute_reply":"2022-05-09T10:03:53.414218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:03:57.233435Z","iopub.execute_input":"2022-05-09T10:03:57.235674Z","iopub.status.idle":"2022-05-09T10:04:02.331422Z","shell.execute_reply.started":"2022-05-09T10:03:57.234165Z","shell.execute_reply":"2022-05-09T10:04:02.330720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"import json\nfrom PIL import Image\nimport torchvision\nimport torch\nimport os\nfrom torch import nn\nimport torch.nn.functional as F\nimport pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-04-15T11:23:42.147789Z","iopub.execute_input":"2022-04-15T11:23:42.148053Z","iopub.status.idle":"2022-04-15T11:23:42.152583Z","shell.execute_reply.started":"2022-04-15T11:23:42.148024Z","shell.execute_reply":"2022-04-15T11:23:42.151729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata_misogyny_test = metadata_misogyny_test.reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:04:07.745418Z","iopub.execute_input":"2022-05-09T10:04:07.745966Z","iopub.status.idle":"2022-05-09T10:04:07.752836Z","shell.execute_reply.started":"2022-05-09T10:04:07.745926Z","shell.execute_reply":"2022-05-09T10:04:07.751851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_unseen = pd.read_json('../input/hatefulmeme/hm_data/hm_data/test_unseen.jsonl',lines=True)\n\ntest_dataset = JsonlDataset(metadata_misogyny_test, '../input/text-hm-embeds/content/text_embeds_hateful', '../input/h2v-768-complete/content/embeddings', '../input/text-mis-embeds/content/text_embeds_misogyny', '../input/misogyny-graph-h2v-lvl-1-complete/misogyny_complete_lvl_1_embedding')\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, num_workers = 2)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:04:09.306060Z","iopub.execute_input":"2022-05-09T10:04:09.306309Z","iopub.status.idle":"2022-05-09T10:04:09.312035Z","shell.execute_reply.started":"2022-05-09T10:04:09.306281Z","shell.execute_reply":"2022-05-09T10:04:09.311288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TestModel = ImageEncoder()\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n#Load dei pesi\nweights = torch.load('./best_model_F1_0.7984_epoca_9.pth',map_location=DEVICE)\nTestModel.load_state_dict(weights)\n\n#Setting model\n\nrunning_accuracy_test = 0.0\nmodel_val = TestModel\nmodel_val.to(DEVICE)\nprint(\"Fatto!\")","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:04:15.729084Z","iopub.execute_input":"2022-05-09T10:04:15.729555Z","iopub.status.idle":"2022-05-09T10:04:16.484019Z","shell.execute_reply.started":"2022-05-09T10:04:15.729518Z","shell.execute_reply":"2022-05-09T10:04:16.483132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata_misogyny_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:04:19.461368Z","iopub.execute_input":"2022-05-09T10:04:19.461925Z","iopub.status.idle":"2022-05-09T10:04:19.477119Z","shell.execute_reply.started":"2022-05-09T10:04:19.461883Z","shell.execute_reply":"2022-05-09T10:04:19.476379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nmodel_val.eval()\nreports = []\nTEST_LOADER=tqdm(test_loader)\n\npredizioni = []\nGT = []\n\nwith torch.no_grad():    \n    for i, data in enumerate(TEST_LOADER):\n        # get the inputs; data is a list of [inputs, labels]\n        text, image,label = data\n        text = text.to(device=DEVICE)\n        #graph = graph.to(device=DEVICE)\n        image = image.to(device=DEVICE)\n        label = label.to(device=DEVICE)\n\n        # forward + backward + optimize\n        outputs = model_val(image, text)\n        #acc = binary_acc(outputs, label)\n        predizioni.append(outputs.detach().cpu().numpy())\n        GT.append(label.detach().cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:04:31.773562Z","iopub.execute_input":"2022-05-09T10:04:31.774141Z","iopub.status.idle":"2022-05-09T10:04:47.352347Z","shell.execute_reply.started":"2022-05-09T10:04:31.774103Z","shell.execute_reply":"2022-05-09T10:04:47.350822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" metriche = {\n     'accuracy' : binary_acc2(unpack(predizioni), unpack(GT)),\n     'AUC' : AUC(unpack(predizioni), unpack(GT)),\n     'F1' : f1(unpack(predizioni), unpack(GT)),\n     'report' : class_report(unpack(predizioni), unpack(GT)),\n }","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:04:50.132801Z","iopub.execute_input":"2022-05-09T10:04:50.133111Z","iopub.status.idle":"2022-05-09T10:04:50.165433Z","shell.execute_reply.started":"2022-05-09T10:04:50.133076Z","shell.execute_reply":"2022-05-09T10:04:50.164728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metriche","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:04:51.109360Z","iopub.execute_input":"2022-05-09T10:04:51.110045Z","iopub.status.idle":"2022-05-09T10:04:51.116428Z","shell.execute_reply.started":"2022-05-09T10:04:51.110000Z","shell.execute_reply":"2022-05-09T10:04:51.115527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}